################ Obtain tweets about florida gators ###############
rt <- rtweet::search_tweets(
"football Florida Gators OR gator", # key words for searching
n = 5000,
include_rts = TRUE,
lang = "en",
retryonratelimit = FALSE
)
################# install required packages #############
check.packages <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
################ Obtain tweets ###################
## get tweets via keywords
rt <- search_tweets(
"COVID", # key words for searching
n = 300,
include_rts = TRUE,
lang = "en",
retryonratelimit = FALSE
)
check.packages(c("wordcloud", "ggplot2", "ggthemes", "rtweet", "dplyr", "quanteda", "tokenizers"))
################ Obtain tweets ###################
## get tweets via keywords
rt <- search_tweets(
"COVID", # key words for searching
n = 300,
include_rts = TRUE,
lang = "en",
retryonratelimit = FALSE
)
## get tweets via user names
usr <- get_timeline(
"nytimes", # Twitter username
n = 300,
check = FALSE
)
## visualization
ggplot(rt, aes(x = is_retweet, fill = is_retweet)) +
geom_bar(stat="count", width = .5)
ggplot(rt, aes(x = friends_count)) +
geom_density(fill = "lightblue", alpha = 0.7)
ggplot(subset(usr, favorite_count > 0 & retweet_count > 0),
aes(x = log(favorite_count), y = log(retweet_count))) +
geom_point(color = "tomato2") +
geom_smooth(se = F, method = "lm", formula = "y ~ x", color = "skyblue")
### preprocess data
texts <- unlist(rtweet::plain_tweets(rt$text)) # obtain texts
texts <- gsub("@|#", "", texts)
# tokenize
wds <- tokenizers::tokenize_tweets(texts, lowercase = TRUE, stopwords = stopwords::stopwords("en"),
strip_punct = TRUE, strip_url = FALSE, simplify = FALSE)
dfs <- lapply(wds, data.frame, stringsAsFactors = F)
dfs <- dplyr::bind_rows(dfs)
words <- table(dfs)
words <- tibble::data_frame(
word = names(words),
n = as.integer(words)
)
words <- as.data.frame(words)
words <- words[!words$word %in% c("florida", "#Florida", "football", "gators", "gator", "uf") ,]
words <- words[!words$word %in% c("COVID", "COVID19", "COVID-19") ,]
words <- table(dfs)
words <- tibble::tibble(
word = names(words),
n = as.integer(words)
)
words <- as.data.frame(words)
words <- words[!words$word %in% c("COVID", "COVID19", "COVID-19") ,]
wordcloud::wordcloud(
words$word, words$n,
min.freq = 1,
max.words=200,
rot.per=0.35,
random.color = FALSE,
colors=brewer.pal(8, "Dark2")
)
words <- words[!words$word %in% c("COVID", "COVID19", "COVID-19", "covid", "covid19") ,]
wordcloud::wordcloud(
words$word, words$n,
min.freq = 1,
max.words=200,
rot.per=0.35,
random.color = FALSE,
colors=brewer.pal(8, "Dark2")
)
wordcloud::wordcloud(
words$word, words$n,
min.freq = 1,
max.words=200,
rot.per=0.35,
random.color = FALSE,
colors=brewer.pal(8, "Dark2")
)
## obtain dictionary
data(data_dictionary_NRC, package = "quanteda.dictionaries")
dict <- dfm(rt$text) %>%
dfm_lookup(dictionary = data_dictionary_NRC)
dict <- convert(dict, to = "data.frame")
dictsum <- as.data.frame(apply(dict[, 2:11], 2, sum))
dictsum_df <- data.frame(emotion = rownames(dictsum), value = dictsum[, 1])
ggplot(dictsum_df, aes(x = emotion, y = value[order(value)])) +
geom_bar(stat = "identity", fill = "tan1", width = 0.5) +
ggthemes::theme_gdocs() +
theme(axis.title.x = element_blank()) +
coord_flip()
wv <- quanteda::dfm(rt$text)
quanteda::textstat_simil(wv[, c("covid", "india")],  method = "cosine", margin = "features")
quanteda::textstat_simil(wv[, c("covid", "china")],  method = "cosine", margin = "features")
quanteda::textstat_simil(wv[, c("covid", "vaccine")],  method = "cosine", margin = "features")
quanteda::textstat_simil(wv[, c("covid", "covid19")],  method = "cosine", margin = "features")
quanteda::textstat_simil(wv[, c("covid", "covid-19")],  method = "cosine", margin = "features")
quanteda::textstat_simil(wv[, c("covid", "travel")],  method = "cosine", margin = "features")
################# install required packages #############
check.packages <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
check.packages(c("wordcloud", "ggplot2", "ggthemes", "rtweet", "dplyr", "quanteda", "tokenizers"))
rt <- search_tweets(
"COVID", # key words for searching
n = 300,
include_rts = TRUE,
lang = "en",
retryonratelimit = FALSE
)
View(rt)
colnames(rt)
usr <- get_timeline(
"nytimes", # Twitter username
n = 300,
check = FALSE
)
View(usr)
View(rt)
rt$text[1:5]
rt$location[1:5]
rt[1:3, 1:5]
rt2 <- subset(rt, retweet_count > 200 & favorite_count > 200)
rt2 <- subset(rt, retweet_count > 50 & favorite_count > 50)
rt2 <- subset(rt, retweet_count > 10 & favorite_count > 10)
rt2 <- subset(usr, retweet_count > 10 & favorite_count > 10)
rt2 <- subset(usr, retweet_count > 100 & favorite_count > 100)
rt2[, c("retweet_count", "text")]
## sort colums
rt2[order(rt2$retweet_count, decreasing = TRUE), ]
## sort colums
rt2[order(rt2$retweet_count, decreasing = TRUE), c("retweet_count", "text")]
## 18 years old; 18 year old; 18-year-old; 18years old; 18yearsold
rt_age <- subset(rt, grepl("[0-9]+(\\s|-)?years?(\\s|-)?old", text, ignore.case = TRUE))
rt_age$text
## group by
group_by(rt, is_retweet) %>% summarise(mean = mean(retweet_count))
group_by(rt, is_retweet) %>% summarise(n = n(retweet_count))
## visualization
ggplot(rt, aes(x = is_retweet, fill = is_retweet)) +
geom_bar(stat="count", width = .5)
ggplot(rt, aes(x = friends_count)) +
geom_density(fill = "lightblue", alpha = 0.7)
ggplot(subset(usr, favorite_count > 0 & retweet_count > 0),
aes(x = log(favorite_count), y = log(retweet_count))) +
geom_point(color = "tomato2") +
geom_smooth(se = F, method = "lm", formula = "y ~ x", color = "skyblue")
### preprocess data
texts <- unlist(rtweet::plain_tweets(rt$text)) # obtain texts
texts <- gsub("@|#", "", texts)
# tokenize
wds <- tokenizers::tokenize_tweets(texts, lowercase = TRUE, stopwords = stopwords::stopwords("en"),
strip_punct = TRUE, strip_url = FALSE, simplify = FALSE)
dfs <- lapply(wds, data.frame, stringsAsFactors = F)
dfs <- dplyr::bind_rows(dfs)
words <- table(dfs)
words <- tibble::tibble(
word = names(words),
n = as.integer(words)
)
words <- as.data.frame(words)
words <- words[!words$word %in% c("COVID", "COVID19", "COVID-19", "covid", "covid19") ,]
wordcloud::wordcloud(
words$word, words$n,
min.freq = 1,
max.words=200,
rot.per=0.35,
random.color = FALSE,
colors=brewer.pal(8, "Dark2")
)
## obtain dictionary
data(data_dictionary_NRC, package = "quanteda.dictionaries")
dict <- dfm(rt$text) %>%
dfm_lookup(dictionary = data_dictionary_NRC)
dict <- convert(dict, to = "data.frame")
dictsum <- as.data.frame(apply(dict[, 2:11], 2, sum))
dictsum_df <- data.frame(emotion = rownames(dictsum), value = dictsum[, 1])
ggplot(dictsum_df, aes(x = emotion, y = value[order(value)])) +
geom_bar(stat = "identity", fill = "tan1", width = 0.5) +
ggthemes::theme_gdocs() +
theme(axis.title.x = element_blank()) +
coord_flip()
wv <- quanteda::dfm(rt$text)
quanteda::textstat_simil(wv[, c("covid", "india")],  method = "cosine", margin = "features")
quanteda::textstat_simil(wv[, c("covid", "china")],  method = "cosine", margin = "features")
?left_join
A <- runif(100, min=-1, max=1)
B <- runif(100, min=-1, max=1)
angle <- function(x,y){
dot.prod <- x%*%y
norm.x <- norm(x,type="2")
norm.y <- norm(y,type="2")
theta <- acos(dot.prod / (norm.x * norm.y))
as.numeric(theta)
}
angle(A, B)
theta <- function(a, b){acos( sum(a*b) / ( sqrt(sum(a * a)) * sqrt(sum(b * b)) ) )}
theta(A,B)
lsa::cosine(A,B)
A
